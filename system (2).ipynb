{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9387c3-f884-4fa5-b8ec-273154e43567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image filtering\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class ImageFilterApp:\n",
    "    def __init__(self, image_path):\n",
    "\n",
    "        self.image = cv2.imread('Pothole2.png', 0)\n",
    "        if self.image is None:\n",
    "            raise ValueError(f\"Error: Could not load image from path: {image_path}\")\n",
    "        self.filtered_image = None\n",
    "\n",
    "    def show_images(self, title1, image1, title2, image2):\n",
    "        \"\"\"Display original and filtered images side by side.\"\"\"\n",
    "        plt.subplot(121)\n",
    "        plt.title(title1)\n",
    "        plt.imshow(image1, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.title(title2)\n",
    "        plt.imshow(image2, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show(block=False)\n",
    "        plt.pause(3)\n",
    "        plt.close()\n",
    "\n",
    "    def apply_median_filter(self, kernel_size):\n",
    "        \"\"\"Apply median filter to the image.\"\"\"\n",
    "        self.filtered_image = cv2.medianBlur(self.image, kernel_size)\n",
    "        self.show_images(\"Original\", self.image, \"Median Filter\", self.filtered_image)\n",
    "\n",
    "    def apply_sobel_filter(self):\n",
    "        \"\"\"Apply Sobel filter to detect edges.\"\"\"\n",
    "        sobelx = cv2.Sobel(self.image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(self.image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        self.filtered_image = cv2.magnitude(sobelx, sobely)\n",
    "        self.show_images(\"Original\", self.image, \"Sobel Filter\", self.filtered_image)\n",
    "\n",
    "    def apply_gaussian_filter(self, kernel_size, sigma):\n",
    "        \"\"\"Apply Gaussian filter to the image.\"\"\"\n",
    "        self.filtered_image = cv2.GaussianBlur(self.image, kernel_size, sigma)\n",
    "        self.show_images(\"Original\", self.image, \"Gaussian Filter\", self.filtered_image)\n",
    "\n",
    "    def apply_averaging_filter(self, kernel_size):\n",
    "        \"\"\"Apply averaging (mean) filter to the image.\"\"\"\n",
    "        self.filtered_image = cv2.blur(self.image, kernel_size)\n",
    "        self.show_images(\"Original\", self.image, \"Averaging Filter\", self.filtered_image)\n",
    "\n",
    "# Menu function to allow user interaction\n",
    "def menu():\n",
    "    print(\"\\nImage Filtering Application\")\n",
    "    print(\"1. Apply Median Filter\")\n",
    "    print(\"2. Apply Sobel Filter\")\n",
    "    print(\"3. Apply Gaussian Filter\")\n",
    "    print(\"4. Apply Averaging Filter\")\n",
    "    print(\"5. Exit\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Image path specified in the code\n",
    "    image_path = \"Pothole2.png\"\n",
    "\n",
    "    try:\n",
    "        app = ImageFilterApp(image_path)\n",
    "\n",
    "        while True:\n",
    "            menu()\n",
    "            choice = input(\"Enter your choice (1-5): \")\n",
    "\n",
    "            if choice == '1':\n",
    "                kernel_size = int(input(\"Enter kernel size for Median Filter (odd number): \"))\n",
    "                app.apply_median_filter(kernel_size)\n",
    "            elif choice == '2':\n",
    "                app.apply_sobel_filter()\n",
    "            elif choice == '3':\n",
    "                kernel_size = int(input(\"Enter kernel size for Gaussian Filter (e.g., 5 for 5x5): \"))\n",
    "                sigma = float(input(\"Enter sigma value for Gaussian Filter (e.g., 0 for default): \"))\n",
    "                app.apply_gaussian_filter((kernel_size, kernel_size), sigma)\n",
    "            elif choice == '4':\n",
    "                kernel_size = int(input(\"Enter kernel size for Averaging Filter (e.g., 5 for 5x5): \"))\n",
    "                app.apply_averaging_filter((kernel_size, kernel_size))\n",
    "            elif choice == '5':\n",
    "                print(\"Exiting...\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid choice. Please try again.\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d12e25-cdff-420e-a830-009ac94b02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image segmentation\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ImageSegmentation:\n",
    "    def __init__(self, image_path):\n",
    "        self.image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        self.color_image = cv2.imread(image_path)  # For Watershed\n",
    "        self.img_blurred = cv2.medianBlur(self.image, 5)\n",
    "\n",
    "    def simple_threshold(self, threshold_value=127):\n",
    "        _, thresh_binary = cv2.threshold(self.img_blurred, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "        plt.imshow(thresh_binary, cmap='gray')\n",
    "        plt.title('Simple Thresholding')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def adaptive_mean_threshold(self):\n",
    "        th_mean = cv2.adaptiveThreshold(self.img_blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        plt.imshow(th_mean, cmap='gray')\n",
    "        plt.title('Adaptive Mean Thresholding')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def adaptive_gaussian_threshold(self):\n",
    "        th_gaussian = cv2.adaptiveThreshold(self.img_blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        plt.imshow(th_gaussian, cmap='gray')\n",
    "        plt.title('Adaptive Gaussian Thresholding')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def otsu_threshold(self):\n",
    "        _, th_otsu = cv2.threshold(self.img_blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        plt.imshow(th_otsu, cmap='gray')\n",
    "        plt.title(\"Otsu's Thresholding\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def region_growing_floodfill(self, seed, lo_diff=10, up_diff=10):\n",
    "        flood_filled_image = self.image.copy()\n",
    "        mask = np.zeros((self.image.shape[0] + 2, self.image.shape[1] + 2), np.uint8)\n",
    "        cv2.floodFill(flood_filled_image, mask, seedPoint=seed, newVal=255, loDiff=(lo_diff,), upDiff=(up_diff,))\n",
    "        plt.imshow(flood_filled_image, cmap='gray')\n",
    "        plt.title('Region Growing Segmentation (Flood Fill)')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def watershed_segmentation(self):\n",
    "        gray = cv2.cvtColor(self.color_image, cv2.COLOR_BGR2GRAY)\n",
    "        _, bin_img = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "        sure_bg = cv2.dilate(bin_img, kernel, iterations=3)\n",
    "        dist = cv2.distanceTransform(bin_img, cv2.DIST_L2, 5)\n",
    "        _, sure_fg = cv2.threshold(dist, 0.5 * dist.max(), 255, cv2.THRESH_BINARY)\n",
    "        sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "        unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "        _, markers = cv2.connectedComponents(sure_fg)\n",
    "        markers += 1\n",
    "        markers[unknown == 255] = 0\n",
    "\n",
    "        markers = cv2.watershed(self.color_image, markers)\n",
    "        self.color_image[markers == -1] = [0, 0, 255]\n",
    "\n",
    "        plt.imshow(cv2.cvtColor(self.color_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Watershed Segmentation')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def main_menu():\n",
    "    print(\"\\nImage Segmentation Menu:\")\n",
    "    print(\"1. Simple Thresholding\")\n",
    "    print(\"2. Adaptive Mean Thresholding\")\n",
    "    print(\"3. Adaptive Gaussian Thresholding\")\n",
    "    print(\"4. Otsu's Thresholding\")\n",
    "    print(\"5. Region Growing (Flood Fill)\")\n",
    "    print(\"6. Watershed Segmentation\")\n",
    "    print(\"0. Exit\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    segmenter = ImageSegmentation('Pothole2.png')\n",
    "\n",
    "    while True:\n",
    "        main_menu()\n",
    "        choice = input(\"Enter your choice (0 to exit): \")\n",
    "\n",
    "        if choice == '1':\n",
    "            segmenter.simple_threshold()\n",
    "        elif choice == '2':\n",
    "            segmenter.adaptive_mean_threshold()\n",
    "        elif choice == '3':\n",
    "            segmenter.adaptive_gaussian_threshold()\n",
    "        elif choice == '4':\n",
    "            segmenter.otsu_threshold()\n",
    "        elif choice == '5':\n",
    "            x = int(input(\"Enter seed point X-coordinate: \"))\n",
    "            y = int(input(\"Enter seed point Y-coordinate: \"))\n",
    "            lo_diff = int(input(\"Enter lower difference threshold: \"))\n",
    "            up_diff = int(input(\"Enter upper difference threshold: \"))\n",
    "            segmenter.region_growing_floodfill(seed=(x, y), lo_diff=lo_diff, up_diff=up_diff)\n",
    "        elif choice == '6':\n",
    "            segmenter.watershed_segmentation()\n",
    "        elif choice == '0':\n",
    "            print(\"Exiting the program.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd8e99-c47c-4baf-831e-a4bb3e77e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image processing\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ImageProcessing:\n",
    "    def __init__(self, image_path1, image_path2):\n",
    "        self.image1 = cv2.imread(image_path1)\n",
    "        self.image2 = cv2.imread(image_path2)\n",
    "        if self.image1 is None or self.image2 is None:\n",
    "            print(\"Error: Unable to load images.\")\n",
    "            exit()\n",
    "\n",
    "    def display_images(self, images, titles):\n",
    "        \"\"\"Display a list of images with corresponding titles.\"\"\"\n",
    "        for img, title in zip(images, titles):\n",
    "            plt.figure()\n",
    "            plt.imshow(img if len(img.shape) == 2 else cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(title)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "    def rotate_image(self):\n",
    "        \"\"\"Rotate the image by a specified angle.\"\"\"\n",
    "        angle = float(input(\"Enter rotation angle in degrees: \"))\n",
    "        h, w = self.image1.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(self.image1, M, (w, h))\n",
    "        self.display_images([self.image1, rotated], ['Original Image', f'Rotated {angle}°'])\n",
    "\n",
    "    def reflect_image(self):\n",
    "        \"\"\"Reflect the image vertically.\"\"\"\n",
    "        reflected = cv2.flip(self.image1, 0)\n",
    "        self.display_images([self.image1, reflected], ['Original Image', 'Reflected Image'])\n",
    "\n",
    "    def scale_image(self):\n",
    "        \"\"\"Scale the image to 70% of its original size.\"\"\"\n",
    "        scaled = cv2.resize(self.image1, None, fx=0.7, fy=0.7, interpolation=cv2.INTER_LINEAR)\n",
    "        self.display_images([self.image1, scaled], ['Original Image', 'Scaled Image'])\n",
    "\n",
    "    def crop_image(self):\n",
    "        \"\"\"Crop the image to remove a border of 100px from top-left and 30px from bottom-right.\"\"\"\n",
    "        x_start, y_start = 100, 100\n",
    "        x_end, y_end = self.image1.shape[1] - 30, self.image1.shape[0] - 30\n",
    "        cropped = self.image1[y_start:y_end, x_start:x_end]\n",
    "        self.display_images([self.image1, cropped], ['Original Image', 'Cropped Image'])\n",
    "\n",
    "    def affine_transform(self):\n",
    "        \"\"\"Apply affine transformation to align two images.\"\"\"\n",
    "        pts1 = np.float32([[50, 50], [200, 50], [50, 200]])\n",
    "        pts2 = np.float32([[60, 60], [210, 50], [60, 210]])\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        aligned = cv2.warpAffine(self.image1, M, (self.image2.shape[1], self.image2.shape[0]))\n",
    "        self.display_images([self.image2, aligned], ['Reference Image', 'Aligned Image'])\n",
    "\n",
    "def main_menu():\n",
    "    \"\"\"Display the main menu options.\"\"\"\n",
    "    print(\"\\n=== Image Processing Menu ===\")\n",
    "    print(\"1. Rotate Image\")\n",
    "    print(\"2. Reflect Image\")\n",
    "    print(\"3. Scale Image\")\n",
    "    print(\"4. Crop Image\")\n",
    "    print(\"5. Affine Transformation\")\n",
    "    print(\"6. Exit\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processor = ImageProcessing('pothole.jpg', 'Pothole2.png')\n",
    "    while True:\n",
    "        main_menu()\n",
    "        choice = input(\"Enter your choice (1-6): \")\n",
    "        if choice == '1':\n",
    "            processor.rotate_image()\n",
    "        elif choice == '2':\n",
    "            processor.reflect_image()\n",
    "        elif choice == '3':\n",
    "            processor.scale_image()\n",
    "        elif choice == '4':\n",
    "            processor.crop_image()\n",
    "        elif choice == '5':\n",
    "            processor.affine_transform()\n",
    "        elif choice == '6':\n",
    "            print(\"Exiting program.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db156131-ae68-4e85-8159-c35430aac29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn visualization\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the plotting configurations\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('image', cmap='magma')\n",
    "\n",
    "# Define the kernel for convolution\n",
    "kernel = tf.constant([[-1, -1, -1],\n",
    "                      [-1,  8, -1],\n",
    "                      [-1, -1, -1]])\n",
    "\n",
    "# Read and process the image\n",
    "image = tf.io.read_file('Pothole2.png')\n",
    "image = tf.io.decode_jpeg(image, channels=1)\n",
    "image = tf.image.resize(image, size=[300, 300])\n",
    "\n",
    "# Convert the image to numpy array and display original grayscale image\n",
    "img = tf.squeeze(image).numpy()\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original Gray Scale image')\n",
    "plt.show()\n",
    "\n",
    "# Prepare the image for convolution\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "# Prepare the kernel\n",
    "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
    "kernel = tf.cast(kernel, dtype=tf.float32)\n",
    "\n",
    "# Perform convolution\n",
    "conv_fn = tf.nn.conv2d\n",
    "image_filter = conv_fn(input=image, filters=kernel, strides=1, padding='SAME')\n",
    "\n",
    "# Apply activation function (ReLU)\n",
    "relu_fn = tf.nn.relu\n",
    "image_detect = relu_fn(image_filter)\n",
    "\n",
    "# Apply max pooling\n",
    "pool = tf.nn.pool\n",
    "image_condense = pool(input=image_detect, window_shape=(2, 2), pooling_type='MAX', strides=(2, 2), padding='SAME')\n",
    "\n",
    "# Plot side by side comparisons\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Original and Convolution image side by side\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.imshow(tf.squeeze(image_filter))\n",
    "plt.axis('off')\n",
    "plt.title('Convolution')\n",
    "\n",
    "# Original and Activation image side by side\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.imshow(tf.squeeze(image_detect))\n",
    "plt.axis('off')\n",
    "plt.title('Activation')\n",
    "\n",
    "# Original and Pooling image side by side\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.imshow(tf.squeeze(image_condense))\n",
    "plt.axis('off')\n",
    "plt.title('Pooling')\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c03f3-537d-4149-b44c-f5267086bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#object detection\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')  # Replace with the desired model (e.g., yolov8s.pt, yolov8m.pt)\n",
    "\n",
    "# Load an image for detection\n",
    "image_path = \"206_png.rf.b0482e388ee10e72bbe47fe6d1e601f7.jpg\"  # Replace with your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform detection\n",
    "results = model(image)\n",
    "\n",
    "# Display results\n",
    "annotated_image = results[0].plot()  # Annotate detections on the image\n",
    "plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Save the annotated image\n",
    "cv2.imwrite(\"output.jpg\", annotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d681a751-b5bf-4260-bfda-7389ce3859c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#facial and gesture\n",
    "\n",
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "while True:\n",
    "    print(\"1. Load the file\")\n",
    "    print(\"2. Detection\")\n",
    "    print(\"3. Exit\")\n",
    "    ch=input(\"Enter your choice\")\n",
    "    if ch=='1':\n",
    "        img_path=input(\"Enter the image path\")\n",
    "        img=cv2.imread(img_path)\n",
    "    elif ch=='2':\n",
    "        results=DeepFace.analyze(img_path,actions=['emotion'],enforce_detection=False)\n",
    "        if not isinstance(results,list):\n",
    "            results=[results]\n",
    "            \n",
    "        for face in results:\n",
    "            region=face['region']\n",
    "            x,y,w,h=region['x'],region['y'],region['w'],region['h']\n",
    "            emotion=face['dominant_emotion']\n",
    "            \n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(img,emotion,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "            \n",
    "        img2=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img2)\n",
    "        plt.title(\"Face Detection\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    elif ch=='3':\n",
    "        print(\"Exiting..\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2387c50-f4ed-4dd5-9d79-caaa9c492d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 10:  Image classification\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # 10 classes\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=64)\n",
    "\n",
    "\n",
    "# CIFAR-10 class labels\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "# Function to predict user-provided image\n",
    "def predict_image():\n",
    "    path = input(\"Enter image path: \")\n",
    "    img = cv2.imread(path)\n",
    "    img2 = cv2.resize(img, (32, 32)) / 255.0  # Resize and normalize\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Prepare the image for prediction\n",
    "    prediction = model.predict(np.expand_dims(img2, axis=0)).argmax()\n",
    "    print(f\"Predicted Class: {class_names[prediction]}\")  # Print the class name\n",
    "\n",
    "\n",
    "# Predict on a new image\n",
    "predict_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270c5cd-065e-4eaa-ae48-6b78aa40269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#denoising\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, _), (x_test, _) = mnist.load_data()  # We don't need the labels for autoencoding\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize\n",
    "\n",
    "# Add noise to the images (to simulate noisy images)\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.randn(*x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.randn(*x_test.shape)\n",
    "\n",
    "# Clip the values to stay between 0 and 1\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "# Expand dimensions to match the input shape of CNN (28x28x1 for grayscale)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "x_train_noisy = np.expand_dims(x_train_noisy, axis=-1)\n",
    "x_test_noisy = np.expand_dims(x_test_noisy, axis=-1)\n",
    "\n",
    "# Build the denoising autoencoder model\n",
    "model = Sequential([\n",
    "    # Encoder\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2), padding='same'),\n",
    "    \n",
    "    # Decoder\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_noisy, x_train, epochs=3, batch_size=64, validation_data=(x_test_noisy, x_test))\n",
    "\n",
    "# Function to predict denoised image\n",
    "def denoise_image():\n",
    "    path = input(\"Enter image path: \")\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  # Read image as grayscale\n",
    "    img_resized = cv2.resize(img, (28, 28)) / 255.0  # Resize and normalize\n",
    "    img_resized = np.expand_dims(img_resized, axis=-1)  # Add channel dimension\n",
    "    \n",
    "    # Add noise to the image\n",
    "    noisy_img = img_resized + noise_factor * np.random.randn(*img_resized.shape)\n",
    "    noisy_img = np.clip(noisy_img, 0., 1.)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(noisy_img.squeeze(), cmap='gray')\n",
    "    plt.title('Noisy Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Denoise the image using the trained model\n",
    "    denoised_img = model.predict(np.expand_dims(noisy_img, axis=0))[0]\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(denoised_img.squeeze(), cmap='gray')\n",
    "    plt.title('Denoised Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Predict on a new noisy image\n",
    "denoise_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39ec73-35a1-42be-a556-3309e31e3d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assignment 13 lstm mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize\n",
    "\n",
    "# Expand dimensions to match the input shape of CNN (28x28x1 for grayscale)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=64)\n",
    "\n",
    "# MNIST class labels (digits 0-9)\n",
    "class_names = [str(i) for i in range(10)]\n",
    "\n",
    "# Function to predict user-provided image\n",
    "def predict_image():\n",
    "    path = input(\"Enter image path: \")\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  # Read image as grayscale\n",
    "    img_resized = cv2.resize(img, (28, 28)) / 255.0  # Resize and normalize\n",
    "    img_resized = np.expand_dims(img_resized, axis=-1)  # Add channel dimension\n",
    "    \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Prepare the image for prediction\n",
    "    prediction = model.predict(np.expand_dims(img_resized, axis=0)).argmax()\n",
    "    print(f\"Predicted Class: {class_names[prediction]}\")  # Print the predicted digit\n",
    "\n",
    "\n",
    "# Predict on a new image\n",
    "predict_image()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
